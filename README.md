# SimpleBackprop
Inspired by [this]( http://iamtrask.github.io/2015/07/12/basic-python-network/ ) post I deciced to write a simple backprop algorithm in Julia. 

The two files show a simple 2 layer and 3 layer ANN for solving a simple classification problem. Sigmoid activation units are used with error weighted derivatives.

Features looking to add include:
- Parameterized layer sizes 
- Momentum
- Dropout
- Mini-batches
